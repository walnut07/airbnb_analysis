{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is to process sentiment analysis on the reviews of airbnb location reviews."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T09:13:39.194922Z",
     "start_time": "2023-11-03T09:13:39.192252Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-03T09:13:39.741781Z",
     "start_time": "2023-11-03T09:13:39.739132Z"
    }
   },
   "outputs": [],
   "source": [
    "city_names = [\"tokyo\", \"sydney\", \"melbourne\", \"singapore\", \"hongkong\", \"taipei\", \"bangkok\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cities_df = dict()\n",
    "for city in city_names:\n",
    "    cities_df[city] = pd.read_csv(\"./data/listings_{c}.csv\".format(c=city))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T09:13:42.308793Z",
     "start_time": "2023-11-03T09:13:40.160374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cities_review_df = dict()\n",
    "for city in city_names:\n",
    "    cities_review_df[city] = pd.read_csv(\"./data/reviews_{c}.csv\".format(c=city))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T09:14:28.934742Z",
     "start_time": "2023-11-03T09:14:22.944212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkurumi/anaconda3/envs/pythonProject/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing comment 1 out of 451682\n",
      "Processing comment 10001 out of 451682\n",
      "Processing comment 20001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 30001 out of 451682\n",
      "Processing comment 40001 out of 451682\n",
      "Processing comment 50001 out of 451682\n",
      "Processing comment 60001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 70001 out of 451682\n",
      "Processing comment 80001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 90001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 100001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 110001 out of 451682\n",
      "Processing comment 120001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 130001 out of 451682\n",
      "Processing comment 140001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 150001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 160001 out of 451682\n",
      "Processing comment 170001 out of 451682\n",
      "Processing comment 180001 out of 451682\n",
      "Processing comment 190001 out of 451682\n",
      "Processing comment 200001 out of 451682\n",
      "Processing comment 210001 out of 451682\n",
      "Processing comment 220001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 230001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 240001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 250001 out of 451682\n",
      "Processing comment 260001 out of 451682\n",
      "Error: 'float' object is not iterable\n",
      "Processing comment 270001 out of 451682\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, DistilBertTokenizer\n",
    "\n",
    "def get_sentiment(text, classifier):\n",
    "    try:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "\n",
    "        if len(tokens) > 510:  # 512 - 2 (for [CLS] and [SEP])\n",
    "            tokens = tokens[:510]\n",
    "\n",
    "        truncated_text = tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "        results = classifier(truncated_text)\n",
    "        sentiment = dict()\n",
    "        for result in results[0]:\n",
    "            sentiment[result[\"label\"]] = result[\"score\"]\n",
    "\n",
    "        return sentiment\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\n",
    "            \"positive\": float(\"NaN\"),\n",
    "            \"negative\": float(\"NaN\"),\n",
    "            \"neutral\": float(\"NaN\")\n",
    "        }\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", return_all_scores=True)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\")\n",
    "\n",
    "sentiment_result = [] # List of dictionaries containing the sentiment result\n",
    "for i, comment in enumerate(cities_review_df['tokyo']['comments']):\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Processing comment {i+1} out of {len(cities_review_df['tokyo']['comments'])}\")\n",
    "    sentiment = get_sentiment(comment, classifier)\n",
    "    sentiment_result.append(sentiment)\n",
    "\n",
    "# Update the dataframe with the sentiment result\n",
    "for i, result in enumerate(sentiment_result):\n",
    "    cities_review_df[\"tokyo\"].loc[i, \"positive\"] = result[\"positive\"]\n",
    "    cities_review_df[\"tokyo\"].loc[i, \"negative\"] = result[\"negative\"]\n",
    "    cities_review_df[\"tokyo\"].loc[i, \"neutral\"] = result[\"neutral\"]\n",
    "\n",
    "# Create a csv\n",
    "cities_review_df[\"tokyo\"].to_csv(\"./data/reviews_tokyo_sentiment.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T11:13:35.639803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
